{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f04d192b3f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#转换思路，用LSTM学习人类曲线后去预判，然后把LOSS当特征\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_track(s):\n",
    "    i,moves,des,flag = s.split(' ')\n",
    "    moves=moves.split(';')[:-1]\n",
    "    moves=[move.split(',') for move in moves]\n",
    "    moves=[[int(ll) for ll in l] for l in moves]\n",
    "    des=[float(p) for p in des.split(',')]\n",
    "    flag=int(flag)\n",
    "#     print(i,moves[0],'->',des,flag)\n",
    "    m = np.matrix(moves)\n",
    "    m = m[np.lexsort(m.T)][0]\n",
    "#     print(m)\n",
    "    return (i,(m[0,0],m[0,1]), m, des, flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_track(track, max_sample=200):\n",
    "    '''\n",
    "    此函数用来扩充取样点，具体扩充方法是每两个点取似然中间点，符合x和y轴上速度相似的设定\n",
    "    为了扩充至少需要三个点，来计算加速度。\n",
    "    我认为，如果只有两个点，那无论什么模型都很难判断轨迹是否是robot，所以不如当作脏数据清洗掉\n",
    "    输入为track的matrix,返回扩充后的matrix，shape'=(shape[0]*2-1, shape[1])\n",
    "    '''\n",
    "    max_exp = max_sample - track.shape[0]#最大扩充点数，使得扩充后的样点数量不大于max_sample\n",
    "    v = get_speed(track)\n",
    "    a = get_acceleration(track)\n",
    "    t = track[1:,-1] - track[:-1,-1]\n",
    "    #加速度相等的推测点算法，结果轨迹不正常\n",
    "#     Xb = track[1:-1,:-1] - np.multiply(v,t[:-1]/2) - np.multiply(a, np.square(t[:-1]/2))*0.5\n",
    "#     Xb_e = track[-2,:-1] + np.multiply(v[-1],t[-1]/2) + np.multiply(a[-1], np.square(t[-1]/2))*0.5\n",
    "#     to_exp = np.vstack([Xb, Xb_e])\n",
    "    #速度相等的推测点算法，结果能接受\n",
    "#     Xb = track[1:-1,:-1] + np.multiply(v,t[1:]/2)\n",
    "#     Xb_s = track[1,:-1] - np.multiply(v[0],t[0]/2)\n",
    "#     to_exp = np.vstack([Xb_s, Xb])\n",
    "    #直接取中间点，对轨迹影响最小\n",
    "    Xb = (track[:-1] + track[1:])/2\n",
    "    to_exp = Xb\n",
    "    expanded =  np.vstack([track, to_exp]) if to_exp.shape[0] <= max_exp else np.vstack([track, to_exp[:max_exp]])\n",
    "    return sort_track(expanded)\n",
    "\n",
    "index, start, track, des, flag = get_track(people[0])\n",
    "# print(track)\n",
    "expand_track(track)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_track(track, max_sample=100):\n",
    "    '''\n",
    "    此函数用于将轨迹中超过数量的点抛弃\n",
    "    抛弃规则是时间距离越近越容易被抛弃\n",
    "    '''\n",
    "    t = track[1:,-1] - track[:-1, -1]\n",
    "    to_drop = track.shape[0] - max_sample\n",
    "    assert to_drop >= 0\n",
    "    return track[np.ix_((np.argsort(track[:,-1],axis=0)>to_drop-1).flat,[0,1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "people = []\n",
    "machine = []\n",
    "test = []\n",
    "with open('dsjtzs_txfz_training.txt') as f:\n",
    "    people = list(filter(lambda l:l.strip().endswith('1'),f.readlines()))\n",
    "    f.seek(0)\n",
    "    machine = list(filter(lambda l:l.strip().endswith('0'),f.readlines()))\n",
    "with open('dsjtzs_txfz_test1.txt') as f:\n",
    "    test = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(2, 2, activation='relu', input_shape=(None, 3)))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "# score = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataS1 = people\n",
    "dataS2 = machine\n",
    "dataA = np.empty(len(dataS1),dtype=np.object)\n",
    "dataB = np.empty(len(dataS2),dtype=np.object)\n",
    "for i,d in enumerate(dataS1):\n",
    "    index, start, track, des, flag = get_track(d)\n",
    "    dataA[i] = track\n",
    "for i,d in enumerate(dataS2):\n",
    "    index, start, track, des, flag = get_track(d)\n",
    "    dataB[i] = track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = dataA\n",
    "X_trainB = dataB\n",
    "\n",
    "Y_trainB = np.zeros(dataB.shape[0]).reshape((-1,1))\n",
    "Y_train = np.ones(dataA.shape[0]).reshape((-1,1))\n",
    "print(dataA[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(np.expand_dims(X_train[0], axis=2), Y_train[0], batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim)\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2pos = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.active = nn.Sigmoid()\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (autograd.Variable(torch.zeros(1, 1, self.hidden_dim)),\n",
    "                autograd.Variable(torch.zeros(1, 1, self.hidden_dim)))\n",
    "        \n",
    "    def forward(self, track):\n",
    "#         print(track)\n",
    "        lstm_out, self.hidden = self.lstm(track.view(len(track), 1, -1), self.hidden)\n",
    "#         dropped = self.dropout(lstm_out.view(len(track), -1))\n",
    "        pos_space = self.hidden2pos(lstm_out.view(len(track), -1))\n",
    "        return self.active(pos_space)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.0342  0.1319  0.0161\n",
      " 0.0355  0.1319  0.0173\n",
      " 0.0375  0.1326  0.0193\n",
      " 0.0403  0.1326  0.0204\n",
      " 0.0484  0.1326  0.0227\n",
      " 0.0565  0.1326  0.0252\n",
      " 0.0653  0.1326  0.0273\n",
      " 0.0701  0.1326  0.0297\n",
      " 0.0755  0.1326  0.0320\n",
      " 0.0795  0.1326  0.0342\n",
      " 0.0822  0.1332  0.0366\n",
      " 0.0856  0.1332  0.0389\n",
      " 0.0904  0.1332  0.0413\n",
      " 0.0951  0.1332  0.0436\n",
      " 0.1026  0.1332  0.0464\n",
      " 0.1107  0.1332  0.0490\n",
      " 0.1195  0.1332  0.0504\n",
      " 0.1242  0.1332  0.0528\n",
      " 0.1269  0.1332  0.0558\n",
      " 0.1283  0.1332  0.0573\n",
      " 0.1290  0.1332  0.0625\n",
      " 0.1310  0.1332  0.0649\n",
      " 0.1330  0.1339  0.0669\n",
      " 0.1405  0.1345  0.0688\n",
      " 0.1425  0.1352  0.0712\n",
      " 0.1432  0.1352  0.0901\n",
      " 0.1439  0.1352  0.0946\n",
      " 0.1446  0.1352  0.1030\n",
      " 0.1452  0.1352  0.1036\n",
      " 0.1466  0.1352  0.1058\n",
      " 0.1466  0.1345  0.1083\n",
      " 0.1473  0.1345  0.1178\n",
      " 0.1479  0.1345  0.1256\n",
      " 0.1493  0.1345  0.1279\n",
      " 0.1500  0.1345  0.1289\n",
      " 0.1513  0.1345  0.1311\n",
      " 0.1527  0.1345  0.1334\n",
      " 0.1540  0.1345  0.1358\n",
      " 0.1547  0.1345  0.1380\n",
      " 0.1554  0.1345  0.1404\n",
      " 0.1561  0.1345  0.1430\n",
      " 0.1567  0.1345  0.1466\n",
      " 0.1581  0.1345  0.1485\n",
      " 0.1595  0.1345  0.1496\n",
      " 0.1615  0.1345  0.1523\n",
      " 0.1622  0.1339  0.1589\n",
      " 0.1635  0.1339  0.1610\n",
      " 0.1662  0.1332  0.1636\n",
      " 0.1676  0.1332  0.1657\n",
      " 0.1683  0.1332  0.1682\n",
      " 0.1676  0.1332  0.2274\n",
      " 0.1669  0.1332  0.2298\n",
      " 0.1662  0.1326  0.2983\n",
      " 0.1649  0.1326  0.3027\n",
      " 0.1649  0.1319  0.3044\n",
      " 0.1642  0.1319  0.3338\n",
      "[torch.FloatTensor of size 56x3]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miller/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "input_dim,hidden_dim, tagset_size = 3,8,1\n",
    "def init_hidden():\n",
    "    # Before we've done anything, we dont have any hidden state.\n",
    "    # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n",
    "    # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "    return (autograd.Variable(torch.zeros(1, 1, hidden_dim)),\n",
    "            autograd.Variable(torch.zeros(1, 1, hidden_dim)))\n",
    "\n",
    "hidden = init_hidden()\n",
    "ll = nn.Linear(hidden_dim, tagset_size)\n",
    "lo = nn.Conv1d(hidden_dim, tagset_size,2)\n",
    "active = nn.Sigmoid()\n",
    "\n",
    "track = dataA[0]\n",
    "track = normalize(track,axis=0)\n",
    "m_lstm = nn.LSTM(3, 8)\n",
    "inputs = autograd.Variable(torch.Tensor(track)).contiguous()\n",
    "print(inputs)\n",
    "lstm_out, hidden = m_lstm(inputs.view(len(inputs), 1, -1), hidden)\n",
    "pos = ll(lstm_out.view(len(lstm_out), -1))\n",
    "# print(active(pos)[-1])\n",
    "targets = autograd.Variable(torch.Tensor([1])).contiguous()\n",
    "# print(targets)\n",
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LSTMTagger(3, 10, 1)\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor = torch.LongTensor(X_train[0])\n",
    "inputs = torch.LongTensor(X_train[0][:,2])\n",
    "targets = torch.LongTensor(X_train[0][:,0:2])\n",
    "# print(tensor.size(), targets.size())\n",
    "# print(X_train[0])\n",
    "# (targets.contiguous()).view(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miller/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.6276\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7054\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7021\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.6999\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7094\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7124\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.6995\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.6935\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7346\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7029\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7184\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7023\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7076\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.6962\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.6866\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.6660\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model, tracks, target):\n",
    "    # Step 1. Remember that Pytorch accumulates gradients.  We need to clear them out\n",
    "    # before each instance\n",
    "    model.zero_grad()\n",
    "    tracks = normalize(tracks, axis=0)\n",
    "\n",
    "    # Also, we need to clear out the hidden state of the LSTM, detaching it from its\n",
    "    # history on the last instance.\n",
    "    model.hidden = model.init_hidden()\n",
    "\n",
    "    # Step 2. Get our inputs ready for the network, that is, turn them into Variables\n",
    "    # of word indices.\n",
    "    inputs = tracks\n",
    "    targets = [target]\n",
    "    inputs = autograd.Variable(torch.Tensor(inputs)).contiguous()\n",
    "    targets = autograd.Variable(torch.Tensor(targets)).contiguous()\n",
    "\n",
    "    # Step 3. Run our forward pass.\n",
    "    tag_scores = model(inputs.float())\n",
    "    loss = loss_function(tag_scores, targets.float())\n",
    "    loss.backward(retain_variables=True)\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "for epoch in range(2): # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for i,tracks in enumerate(X_train):\n",
    "        if i < 400:\n",
    "            train(model, tracks, 1)\n",
    "            loss = train(model, dataB[i], 0)\n",
    "        if i%50 == 0:\n",
    "            print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([193, 4])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        :param **kwargs: output_dim=4: output dimension of LSTM layer; \n",
    "        activation_lstm='tanh': activation function for LSTM layers; \n",
    "        activation_dense='relu': activation function for Dense layer; \n",
    "        activation_last='sigmoid': activation function for last layer; \n",
    "        drop_out=0.2: fraction of input units to drop; \n",
    "        np_epoch=10, the number of epoches to train the model. \n",
    "            epoch is one forward pass and one backward pass of all the training examples; \n",
    "        batch_size=32: number of samples per gradient update. \n",
    "            The higher the batch size, the more memory space you'll need; \n",
    "        loss='mean_square_error': loss function; \n",
    "        optimizer='rmsprop'\n",
    "        \"\"\"\n",
    "        self.output_dim = kwargs.get('output_dim', 8)\n",
    "        self.activation_lstm = kwargs.get('activation_lstm', 'relu')\n",
    "        self.activation_dense = kwargs.get('activation_dense', 'relu')\n",
    "        self.activation_last = kwargs.get('activation_last', 'softmax')    # softmax for multiple output\n",
    "        self.dense_layer = kwargs.get('dense_layer', 2)     # at least 2 layers\n",
    "        self.lstm_layer = kwargs.get('lstm_layer', 2)\n",
    "        self.drop_out = kwargs.get('drop_out', 0.2)\n",
    "        self.nb_epoch = kwargs.get('nb_epoch', 10)\n",
    "        self.batch_size = kwargs.get('batch_size', 100)\n",
    "        self.loss = kwargs.get('loss', 'categorical_crossentropy')\n",
    "        self.optimizer = kwargs.get('optimizer', 'rmsprop')\n",
    "\n",
    "    def NN_model(self, trainX, trainY, testX, testY):\n",
    "        \"\"\"\n",
    "        :param trainX: training data set\n",
    "        :param trainY: expect value of training data\n",
    "        :param testX: test data set\n",
    "        :param testY: epect value of test data\n",
    "        :return: model after training\n",
    "        \"\"\"\n",
    "        print(\"Training model is LSTM network!\")\n",
    "        input_dim = trainX[1].shape[1]\n",
    "        output_dim = trainY.shape[1] # one-hot label\n",
    "        # print predefined parameters of current model:\n",
    "        model = Sequential()\n",
    "        # applying a LSTM layer with x dim output and y dim input. Use dropout parameter to avoid overfitting\n",
    "        model.add(LSTM(output_dim=self.output_dim,\n",
    "                       input_dim=input_dim,\n",
    "                       activation=self.activation_lstm,\n",
    "                       dropout_U=self.drop_out,\n",
    "                       return_sequences=True))\n",
    "        for i in range(self.lstm_layer-2):\n",
    "            model.add(LSTM(output_dim=self.output_dim,\n",
    "                       input_dim=self.output_dim,\n",
    "                       activation=self.activation_lstm,\n",
    "                       dropout_U=self.drop_out,\n",
    "                       return_sequences=True))\n",
    "        # argument return_sequences should be false in last lstm layer to avoid input dimension incompatibility with dense layer\n",
    "            model.add(LSTM(output_dim=self.output_dim,\n",
    "                       input_dim=self.output_dim,\n",
    "                       activation=self.activation_lstm,\n",
    "                       dropout_U=self.drop_out))\n",
    "        for i in range(self.dense_layer-1):\n",
    "            model.add(Dense(output_dim=self.output_dim,\n",
    "                        activation=self.activation_last))\n",
    "            model.add(Dense(output_dim=output_dim,\n",
    "                        input_dim=self.output_dim,\n",
    "                        activation=self.activation_last))\n",
    "        # configure the learning process\n",
    "            model.compile(loss=self.loss, optimizer=self.optimizer, metrics=['accuracy'])\n",
    "        # train the model with fixed number of epoches\n",
    "            model.fit(x=trainX, y=trainY, nb_epoch=self.nb_epoch, batch_size=self.batch_size, validation_data=(testX, testY))\n",
    "        # store model to json file\n",
    "            model_json = model.to_json()\n",
    "        with open(model_path, \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        # store model weights to hdf5 file\n",
    "        if model_weight_path:\n",
    "            if os.path.exists(model_weight_path):\n",
    "                os.remove(model_weight_path)\n",
    "            model.save_weights(model_weight_path) # eg: model_weight.h5\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = NeuralNetwork(output_dim=3, batch_size=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
